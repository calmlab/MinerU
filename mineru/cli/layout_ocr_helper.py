"""
Layout OCR Helper Module

This module provides custom functions for the /layout_ocr API endpoint.
It preserves character-level OCR information (chars) that would normally be deleted.

⚠️ IMPORTANT: This module does NOT modify any existing MinerU code.
All custom logic is isolated here to avoid conflicts with MinerU updates.
"""

import copy
import statistics
import re
from typing import List, Dict, Any, Optional, Tuple
from PIL import Image
from loguru import logger


def __replace_ligatures(text: str) -> str:
    """
    Replace ligature characters with normal characters.
    (Copied from mineru/utils/span_pre_proc.py)

    Args:
        text: Input text

    Returns:
        Text with ligatures replaced
    """
    ligatures = {
        'ﬁ': 'fi', 'ﬂ': 'fl', 'ﬀ': 'ff', 'ﬃ': 'ffi', 'ﬄ': 'ffl', 'ﬅ': 'ft', 'ﬆ': 'st'
    }
    return re.sub('|'.join(map(re.escape, ligatures.keys())), lambda m: ligatures[m.group()], text)


def __replace_unicode(text: str) -> str:
    """
    Replace special unicode characters.
    (Copied from mineru/utils/span_pre_proc.py)

    Args:
        text: Input text

    Returns:
        Text with special unicode replaced
    """
    replacements = {
        '\r\n': '', '\u0002': '-',
    }
    return re.sub('|'.join(map(re.escape, replacements.keys())), lambda m: replacements[m.group()], text)


def chars_to_content_keep(span: Dict[str, Any], keep_chars: bool = True) -> Dict[str, Any]:
    """
    Convert chars array to content string in a span, optionally keeping chars.
    This is a modified version of mineru/utils/span_pre_proc.py:chars_to_content()

    Args:
        span: Span dictionary containing 'chars' array
        keep_chars: If True, preserve 'chars' array after conversion (default: True)

    Returns:
        Modified span dictionary
    """
    if 'chars' not in span or len(span['chars']) == 0:
        span['content'] = span.get('content', '')
        return span

    # Sort chars by char_idx
    span['chars'] = sorted(span['chars'], key=lambda x: x.get('char_idx', 0))

    # Calculate the width of each character
    char_widths = [char['bbox'][2] - char['bbox'][0] for char in span['chars']]
    if len(char_widths) == 0:
        span['content'] = ''
        return span

    median_width = statistics.median(char_widths)

    # Build content string with proper spacing
    content = ''
    for i, char in enumerate(span['chars']):
        char1 = char
        char2 = span['chars'][i + 1] if i + 1 < len(span['chars']) else None

        if (char2 and
            char2['bbox'][0] - char1['bbox'][2] > median_width * 0.25 and
            char['char'] != ' ' and char2['char'] != ' '):
            content += f"{char['char']} "
        else:
            content += char['char']

    # Apply text replacements
    content = __replace_unicode(content)
    content = __replace_ligatures(content)
    span['content'] = content.strip()

    # Only delete chars if keep_chars is False
    if not keep_chars:
        del span['chars']

    return span


def is_char_in_span_bbox(char_bbox: List[float], span_bbox: List[float]) -> bool:
    """
    Check if a character is within a span's bounding box.

    Args:
        char_bbox: Character bbox [x0, y0, x1, y1]
        span_bbox: Span bbox [x0, y0, x1, y1]

    Returns:
        True if char center is within span bbox
    """
    char_center_x = (char_bbox[0] + char_bbox[2]) / 2
    char_center_y = (char_bbox[1] + char_bbox[3]) / 2

    return (span_bbox[0] <= char_center_x <= span_bbox[2] and
            span_bbox[1] <= char_center_y <= span_bbox[3])


def restore_chars_to_middle_json(middle_json: Dict[str, Any], pdf_doc) -> Dict[str, Any]:
    """
    Restore character-level information to middle_json spans.

    Strategy:
    1. Extract all char info from PDF pages
    2. Map chars to spans based on bbox overlap
    3. Convert chars to content while preserving char data

    Args:
        middle_json: middle_json generated by MinerU pipeline
        pdf_doc: PyMuPDF document object

    Returns:
        middle_json with chars information restored
    """
    from mineru.utils.pdf_text_tool import get_page

    for page_info in middle_json.get("pdf_info", []):
        page_idx = page_info["page_idx"]

        try:
            # Extract char information from PDF page
            pdf_page = pdf_doc[page_idx]
            page_dict = get_page(pdf_page)

            # Collect all chars from the page
            all_chars = []
            for block in page_dict.get('blocks', []):
                for line in block.get('lines', []):
                    # Skip rotated lines
                    if 0 < abs(line.get('rotation', 0)) < 90:
                        continue
                    for span_dict in line.get('spans', []):
                        for char in span_dict.get('chars', []):
                            all_chars.append(char)

            # Process preproc_blocks
            blocks = page_info.get("preproc_blocks", [])
            _restore_chars_to_blocks(blocks, all_chars)

            # Process discarded_blocks
            discarded_blocks = page_info.get("discarded_blocks", [])
            _restore_chars_to_blocks(discarded_blocks, all_chars)

        except Exception as e:
            logger.warning(f"Failed to restore chars for page {page_idx}: {e}")
            continue

    return middle_json


def _restore_chars_to_blocks(blocks: List[Dict[str, Any]], all_chars: List[Dict[str, Any]]):
    """
    Restore chars to blocks (helper function).

    Args:
        blocks: List of blocks
        all_chars: List of all chars from the page
    """
    for block in blocks:
        for line in block.get("lines", []):
            for span in line.get("spans", []):
                # Only process text-type spans
                if span.get("type") in ["text", "inline_equation"]:
                    span['chars'] = []
                    span_bbox = span['bbox']

                    # Find chars that overlap with this span
                    for char in all_chars:
                        if is_char_in_span_bbox(char['bbox'], span_bbox):
                            span['chars'].append(char)

                    # Convert chars to content (keeping chars)
                    if len(span['chars']) > 0:
                        chars_to_content_keep(span, keep_chars=True)
                    else:
                        # No chars found, keep existing content
                        span['content'] = span.get('content', '')


def result_to_middle_json_from_images(
    model_list,
    images_list,
    image_writer,
    lang=None,
    ocr_enable=False,
    formula_enabled=True
):
    """
    Convert model results to middle_json format WITHOUT using pdf_doc.

    This is a modified version of result_to_middle_json() that works with
    images directly, without requiring a PDF document.

    Args:
        model_list: List of model results per page
        images_list: List of image dictionaries
        image_writer: Image writer for saving extracted images
        lang: OCR language
        ocr_enable: Enable OCR
        formula_enabled: Enable formula detection

    Returns:
        middle_json dictionary
    """
    from mineru.backend.pipeline.model_json_to_middle_json import page_model_info_to_page_info
    from mineru.backend.pipeline.model_init import AtomModelSingleton
    from mineru.utils.config_reader import get_formula_enable
    from mineru.version import __version__
    from tqdm import tqdm

    middle_json = {"pdf_info": [], "_backend": "pipeline", "_version_name": __version__}
    formula_enabled = get_formula_enable(formula_enabled)

    for page_index, page_model_info in tqdm(enumerate(model_list), total=len(model_list), desc="Processing pages"):
        image_dict = images_list[page_index]

        # Create a mock page object with get_size() method
        class MockPage:
            def __init__(self, width, height):
                self._width = width
                self._height = height

            def get_size(self):
                return (self._width, self._height)

        # Use image dimensions instead of PDF page dimensions
        pil_img = image_dict['img_pil']
        mock_page = MockPage(pil_img.width, pil_img.height)

        page_info = page_model_info_to_page_info(
            page_model_info, image_dict, mock_page, image_writer,
            page_index, ocr_enable=ocr_enable, formula_enabled=formula_enabled
        )

        if page_info is None:
            from mineru.backend.pipeline.model_json_to_middle_json import make_page_info_dict
            page_w, page_h = pil_img.width, pil_img.height
            page_info = make_page_info_dict([], page_index, page_w, page_h, [])

        middle_json["pdf_info"].append(page_info)

    # Post-OCR processing (same as original)
    need_ocr_list = []
    img_crop_list = []
    text_block_list = []

    for page_info in middle_json["pdf_info"]:
        for block in page_info['preproc_blocks']:
            if block['type'] in ['table', 'image']:
                for sub_block in block['blocks']:
                    if sub_block['type'] in ['image_caption', 'image_footnote', 'table_caption', 'table_footnote']:
                        text_block_list.append(sub_block)
            elif block['type'] in ['text', 'title']:
                text_block_list.append(block)
        for block in page_info['discarded_blocks']:
            text_block_list.append(block)

    for block in text_block_list:
        for line in block['lines']:
            for span in line['spans']:
                if 'np_img' in span:
                    need_ocr_list.append(span)
                    img_crop_list.append(span['np_img'])
                    span.pop('np_img')

    if len(img_crop_list) > 0:
        atom_model_manager = AtomModelSingleton()
        ocr_model = atom_model_manager.get_atom_model(
            atom_model_name='ocr',
            det_db_box_thresh=0.3,
            lang=lang
        )
        ocr_res_list = ocr_model.ocr(img_crop_list, det=False, tqdm_enable=True)[0]
        assert len(ocr_res_list) == len(need_ocr_list)

        for span, ocr_res in zip(need_ocr_list, ocr_res_list):
            if ocr_res is None:
                span['content'] = ''
            else:
                span['content'] = ocr_res[1][0]

    return middle_json


def pdf_bytes_to_pil_images(
    pdf_bytes: bytes,
    start_page_id: int = 0,
    end_page_id: int = 99999
) -> Tuple[List[Image.Image], List[Tuple[int, int]]]:
    """
    Convert PDF bytes to PIL Image list.

    This function converts PDF pages to PIL Images using PyMuPDF (fitz).
    Images are rendered at 2x scale for better quality.

    Args:
        pdf_bytes: PDF file bytes
        start_page_id: Start page index (0-based)
        end_page_id: End page index (inclusive)

    Returns:
        Tuple of (pil_images, page_sizes)
        - pil_images: List of PIL Image objects
        - page_sizes: List of (width, height) tuples
    """
    import fitz  # PyMuPDF

    pil_images = []
    page_sizes = []

    # Open PDF from bytes
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")

    # Apply page range
    start_idx = max(0, start_page_id)
    end_idx = min(len(doc), end_page_id + 1)

    logger.info(f"Converting PDF pages {start_idx} to {end_idx - 1} to images...")

    for page_idx in range(start_idx, end_idx):
        page = doc[page_idx]

        # Render page to image (2x scale for quality)
        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))

        # Convert to PIL Image
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

        pil_images.append(img)
        page_sizes.append((img.width, img.height))

    doc.close()

    logger.info(f"Converted {len(pil_images)} pages to images")

    return pil_images, page_sizes


async def process_images_with_layout_ocr(
    pil_images: List[Image.Image],
    page_sizes: List[Tuple[int, int]],
    pdf_file_names: List[str],
    p_lang_list: List[str],
    parse_method: str,
    output_dir: str,
    start_page_id: int = 0,
    **config
) -> List[Dict[str, Any]]:
    """
    PIL Image 리스트를 직접 처리하여 layout_ocr 수행

    ⚠️ 중요: PDF 파일을 절대 생성하지 않음
    - batch_image_analyze()로 이미지 직접 처리
    - restore_chars_to_middle_json() 호출 생략 (PDF 텍스트 레이어 불필요)
    - OCR 결과에 이미 char 정보 포함되어 있음

    Args:
        pil_images: PIL Image 리스트
        page_sizes: (width, height) 튜플 리스트
        pdf_file_names: 파일명 리스트
        p_lang_list: 언어 리스트
        parse_method: auto/ocr/txt
        output_dir: 출력 디렉토리
        start_page_id: 시작 페이지 인덱스
        **config: 추가 설정

    Returns:
        middle_json_list (PDF 텍스트 레이어 추출 없이)
    """
    from mineru.backend.pipeline.pipeline_analyze import batch_image_analyze
    from mineru.backend.pipeline.model_json_to_middle_json import result_to_middle_json
    from mineru.cli.common import prepare_env
    from mineru.data.data_reader_writer import FileBasedDataWriter

    logger.info(f"Processing {len(pil_images)} PIL images directly with batch_image_analyze...")

    # Step 1: Prepare images with language info
    # Format: List[Tuple[Image.Image, bool, str]]
    images_with_extra_info = []
    for idx, pil_img in enumerate(pil_images):
        lang = p_lang_list[0] if len(p_lang_list) > 0 else 'ch'
        ocr_enable = (parse_method == 'ocr' or parse_method == 'auto')
        images_with_extra_info.append((pil_img, ocr_enable, lang))

    # Step 2: Run batch_image_analyze (직접 이미지 처리, PDF 생성 안 함!)
    logger.info("Running batch_image_analyze on PIL images...")
    batch_results = batch_image_analyze(
        images_with_extra_info,
        formula_enable=True,
        table_enable=True
    )
    logger.info(f"Batch analysis completed for {len(batch_results)} pages")

    # Step 3: Build infer_results structure
    # Format: infer_results[pdf_idx][page_idx] = {'layout_dets': result, 'page_info': page_info_dict}
    infer_results = [[]]  # One file (all images belong to first file)

    for page_idx, (pil_img, result) in enumerate(zip(pil_images, batch_results)):
        page_info_dict = {
            'page_no': page_idx,
            'width': pil_img.width,
            'height': pil_img.height
        }
        page_dict = {
            'layout_dets': result,
            'page_info': page_info_dict
        }
        infer_results[0].append(page_dict)

    # Step 4: Build images_list structure
    all_image_lists = [[]]
    for page_idx, pil_img in enumerate(pil_images):
        img_dict = {
            'img_pil': pil_img,
            'page_idx': page_idx,
            'scale': 1.0  # 이미지 직접 처리 시 좌표 변환 불필요 (픽셀 → 픽셀)
        }
        all_image_lists[0].append(img_dict)

    # Step 5: Generate middle_json (PDF 없이!)
    middle_json_list = []
    for idx, model_list in enumerate(infer_results):
        pdf_file_name = pdf_file_names[idx] if idx < len(pdf_file_names) else 'images'
        local_image_dir, local_md_dir = prepare_env(output_dir, pdf_file_name, parse_method)
        image_writer = FileBasedDataWriter(local_image_dir)

        images_list = all_image_lists[idx]
        _lang = p_lang_list[idx] if idx < len(p_lang_list) else 'ch'
        _ocr_enable = True

        # Generate middle_json using PDF-free version
        # ⚠️ result_to_middle_json_from_images() - PDF 절대 사용 안 함!
        logger.info(f"Generating middle_json for {pdf_file_name}...")
        middle_json = result_to_middle_json_from_images(
            model_list, images_list, image_writer,
            _lang, _ocr_enable, formula_enabled=True
        )

        # ⚠️ restore_chars_to_middle_json() 호출 생략!
        # 이유: PDF 텍스트 레이어가 없으므로 불필요
        # OCR 결과에 이미 char 정보 포함되어 있음

        # Adjust page indices
        if start_page_id > 0:
            for page_info in middle_json.get("pdf_info", []):
                page_info["page_idx"] += start_page_id

        middle_json_list.append(middle_json)

    logger.info(f"Processing completed for {len(middle_json_list)} file(s)")
    return middle_json_list


async def aio_layout_ocr_parse(
    output_dir: str,
    pdf_file_names: List[str],
    pdf_bytes_list: List[bytes],
    p_lang_list: List[str],
    parse_method: str = "auto",
    start_page_id: int = 0,
    end_page_id: Optional[int] = None,
    **kwargs,
) -> List[Dict[str, Any]]:
    """
    Independent parsing pipeline for layout_ocr API (PDF bytes input).

    This function now delegates to process_images_with_layout_ocr() after
    converting PDF bytes to PIL Images. This allows code reuse between
    /layout_ocr and /layout_ocr_images endpoints.

    Args:
        output_dir: Output directory for temporary files
        pdf_file_names: List of PDF file names
        pdf_bytes_list: List of PDF bytes
        p_lang_list: List of OCR languages
        parse_method: Parsing method (auto/ocr/txt)
        start_page_id: Start page index
        end_page_id: End page index
        **kwargs: Additional arguments

    Returns:
        List of middle_json dictionaries with chars information
    """
    from mineru.cli.common import _prepare_pdf_bytes

    # Prepare PDF bytes (apply page range)
    if end_page_id is None:
        end_page_id = 99999
    pdf_bytes_list = _prepare_pdf_bytes(pdf_bytes_list, start_page_id, end_page_id)

    # Convert PDF bytes to PIL Images
    all_pil_images = []
    all_page_sizes = []

    for pdf_bytes in pdf_bytes_list:
        # Note: We pass 0 and 99999 here because _prepare_pdf_bytes already applied the range
        pil_images, page_sizes = pdf_bytes_to_pil_images(pdf_bytes, 0, 99999)
        all_pil_images.extend(pil_images)
        all_page_sizes.extend(page_sizes)

    # Call common processing function
    return await process_images_with_layout_ocr(
        pil_images=all_pil_images,
        page_sizes=all_page_sizes,
        pdf_file_names=pdf_file_names,
        p_lang_list=p_lang_list,
        parse_method=parse_method,
        output_dir=output_dir,
        start_page_id=start_page_id,
        **kwargs
    )


def format_layout_ocr_result(
    middle_json_list: List[Dict[str, Any]],
    pdf_file_names: List[str],
    include_discarded: bool = False
) -> Dict[str, Any]:
    """
    Format middle_json to layout_ocr API response format.

    Args:
        middle_json_list: List of middle_json dictionaries
        pdf_file_names: List of PDF file names
        include_discarded: Whether to include discarded blocks (headers/footers)

    Returns:
        Formatted response dictionary
    """
    from mineru.version import __version__

    result = {
        "status": "success",
        "backend": "pipeline",
        "version": __version__,
        "files": []
    }

    for pdf_idx, middle_json in enumerate(middle_json_list):
        file_result = {
            "filename": pdf_file_names[pdf_idx],
            "pages": []
        }

        for page_info in middle_json.get("pdf_info", []):
            page_data = {
                "page_index": page_info["page_idx"],
                "page_size": {
                    "width": page_info["page_size"][0],
                    "height": page_info["page_size"][1]
                },
                "layout_boxes": []
            }

            box_id = 0
            page_height = page_info["page_size"][1]  # Get page height for bbox conversion

            # Process main blocks (para_blocks or preproc_blocks)
            blocks = page_info.get("para_blocks") or page_info.get("preproc_blocks", [])
            for block in blocks:
                layout_box = format_block_to_layout_box(block, box_id, page_height)
                if layout_box:
                    page_data["layout_boxes"].append(layout_box)
                    box_id += 1

            # Process discarded blocks if requested
            if include_discarded:
                page_data["discarded_boxes"] = []
                for block in page_info.get("discarded_blocks", []):
                    layout_box = format_block_to_layout_box(block, box_id, page_height)
                    if layout_box:
                        layout_box["is_discarded"] = True
                        page_data["discarded_boxes"].append(layout_box)
                        box_id += 1

            file_result["pages"].append(page_data)

        result["files"].append(file_result)

    return result


def format_block_to_layout_box(block: Dict[str, Any], box_id: int, page_height: int) -> Optional[Dict[str, Any]]:
    """
    Convert a block to layout_box format with y-axis flipped coordinates.

    MinerU uses PDF coordinate system (origin at bottom-left, y increases upward).
    This function converts to image coordinate system (origin at top-left, y increases downward).

    Args:
        block: Block dictionary (preproc_block or para_block)
        box_id: Box ID
        page_height: Page height in pixels (needed for y-axis flip)

    Returns:
        layout_box dictionary or None if invalid
    """
    block_type = block.get("type")
    if not block_type:
        return None

    # Convert block bbox (PDF coordinates -> Image coordinates)
    original_bbox = block.get("bbox")
    if original_bbox:
        x0, y0, x1, y1 = original_bbox
        flipped_bbox = [
            x0,
            page_height - y1,  # Flip y-axis
            x1,
            page_height - y0   # Flip y-axis
        ]
    else:
        flipped_bbox = None

    # Basic information
    layout_box = {
        "box_id": box_id,
        "box_type": block_type,
        "bbox": flipped_bbox,
    }

    # Add group_id if present (for tables/images)
    if "group_id" in block:
        layout_box["group_id"] = block["group_id"]

    # Process lines
    lines = block.get("lines", [])
    layout_box["lines"] = []

    for line_idx, line in enumerate(lines):
        # Convert line bbox (PDF coordinates -> Image coordinates)
        original_line_bbox = line.get("bbox")
        if original_line_bbox:
            lx0, ly0, lx1, ly1 = original_line_bbox
            flipped_line_bbox = [
                lx0,
                page_height - ly1,  # Flip y-axis
                lx1,
                page_height - ly0   # Flip y-axis
            ]
        else:
            flipped_line_bbox = None

        line_data = {
            "line_index": line.get("index", line_idx),
            "bbox": flipped_line_bbox,
            "spans": []
        }

        # Process spans
        for span in line.get("spans", []):
            # Convert span bbox (PDF coordinates -> Image coordinates)
            original_span_bbox = span.get("bbox")
            if original_span_bbox:
                sx0, sy0, sx1, sy1 = original_span_bbox
                flipped_span_bbox = [
                    sx0,
                    page_height - sy1,  # Flip y-axis
                    sx1,
                    page_height - sy0   # Flip y-axis
                ]
            else:
                flipped_span_bbox = None

            span_data = {
                "type": span.get("type"),
                "bbox": flipped_span_bbox,
                "score": span.get("score"),
                "content": span.get("content", "")
            }

            # Add special type-specific data
            span_type = span.get("type")
            if span_type == "table":
                if "html" in span:
                    span_data["html"] = span["html"]
                if "latex" in span:
                    span_data["latex"] = span["latex"]
            elif span_type == "image":
                if "image_path" in span:
                    span_data["image_path"] = span["image_path"]
            elif span_type in ["interline_equation", "inline_equation"]:
                if "latex" in span:
                    span_data["latex"] = span["latex"]

            # Add characters if present (with y-axis flipped coordinates)
            if "chars" in span and len(span["chars"]) > 0:
                span_data["characters"] = []
                for i, char in enumerate(span["chars"]):
                    # Convert character bbox (PDF coordinates -> Image coordinates)
                    char_bbox = char.get("bbox")
                    if char_bbox:
                        cx0, cy0, cx1, cy1 = char_bbox
                        flipped_char_bbox = [
                            cx0,
                            page_height - cy1,  # Flip y-axis
                            cx1,
                            page_height - cy0   # Flip y-axis
                        ]
                    else:
                        flipped_char_bbox = None

                    span_data["characters"].append({
                        "char": char["char"],
                        "bbox": flipped_char_bbox,
                        "char_index": char.get("char_idx", i)
                    })

            line_data["spans"].append(span_data)

        # Generate line text
        line_text = " ".join(
            span.get("content", "")
            for span in line.get("spans", [])
            if span.get("type") in ["text", "inline_equation"]
        )
        line_data["text"] = line_text.strip()

        layout_box["lines"].append(line_data)

    return layout_box
