"""
Layout OCR Helper Module

This module provides custom functions for the /layout_ocr API endpoint.
It preserves character-level OCR information (chars) that would normally be deleted.

⚠️ IMPORTANT: This module does NOT modify any existing MinerU code.
All custom logic is isolated here to avoid conflicts with MinerU updates.
"""

import copy
import statistics
import re
from typing import List, Dict, Any, Optional
from loguru import logger


def __replace_ligatures(text: str) -> str:
    """
    Replace ligature characters with normal characters.
    (Copied from mineru/utils/span_pre_proc.py)

    Args:
        text: Input text

    Returns:
        Text with ligatures replaced
    """
    ligatures = {
        'ﬁ': 'fi', 'ﬂ': 'fl', 'ﬀ': 'ff', 'ﬃ': 'ffi', 'ﬄ': 'ffl', 'ﬅ': 'ft', 'ﬆ': 'st'
    }
    return re.sub('|'.join(map(re.escape, ligatures.keys())), lambda m: ligatures[m.group()], text)


def __replace_unicode(text: str) -> str:
    """
    Replace special unicode characters.
    (Copied from mineru/utils/span_pre_proc.py)

    Args:
        text: Input text

    Returns:
        Text with special unicode replaced
    """
    replacements = {
        '\r\n': '', '\u0002': '-',
    }
    return re.sub('|'.join(map(re.escape, replacements.keys())), lambda m: replacements[m.group()], text)


def chars_to_content_keep(span: Dict[str, Any], keep_chars: bool = True) -> Dict[str, Any]:
    """
    Convert chars array to content string in a span, optionally keeping chars.
    This is a modified version of mineru/utils/span_pre_proc.py:chars_to_content()

    Args:
        span: Span dictionary containing 'chars' array
        keep_chars: If True, preserve 'chars' array after conversion (default: True)

    Returns:
        Modified span dictionary
    """
    if 'chars' not in span or len(span['chars']) == 0:
        span['content'] = span.get('content', '')
        return span

    # Sort chars by char_idx
    span['chars'] = sorted(span['chars'], key=lambda x: x.get('char_idx', 0))

    # Calculate the width of each character
    char_widths = [char['bbox'][2] - char['bbox'][0] for char in span['chars']]
    if len(char_widths) == 0:
        span['content'] = ''
        return span

    median_width = statistics.median(char_widths)

    # Build content string with proper spacing
    content = ''
    for i, char in enumerate(span['chars']):
        char1 = char
        char2 = span['chars'][i + 1] if i + 1 < len(span['chars']) else None

        if (char2 and
            char2['bbox'][0] - char1['bbox'][2] > median_width * 0.25 and
            char['char'] != ' ' and char2['char'] != ' '):
            content += f"{char['char']} "
        else:
            content += char['char']

    # Apply text replacements
    content = __replace_unicode(content)
    content = __replace_ligatures(content)
    span['content'] = content.strip()

    # Only delete chars if keep_chars is False
    if not keep_chars:
        del span['chars']

    return span


def is_char_in_span_bbox(char_bbox: List[float], span_bbox: List[float]) -> bool:
    """
    Check if a character is within a span's bounding box.

    Args:
        char_bbox: Character bbox [x0, y0, x1, y1]
        span_bbox: Span bbox [x0, y0, x1, y1]

    Returns:
        True if char center is within span bbox
    """
    char_center_x = (char_bbox[0] + char_bbox[2]) / 2
    char_center_y = (char_bbox[1] + char_bbox[3]) / 2

    return (span_bbox[0] <= char_center_x <= span_bbox[2] and
            span_bbox[1] <= char_center_y <= span_bbox[3])


def restore_chars_to_middle_json(middle_json: Dict[str, Any], pdf_doc) -> Dict[str, Any]:
    """
    Restore character-level information to middle_json spans.

    Strategy:
    1. Extract all char info from PDF pages
    2. Map chars to spans based on bbox overlap
    3. Convert chars to content while preserving char data

    Args:
        middle_json: middle_json generated by MinerU pipeline
        pdf_doc: PyMuPDF document object

    Returns:
        middle_json with chars information restored
    """
    from mineru.utils.pdf_text_tool import get_page

    for page_info in middle_json.get("pdf_info", []):
        page_idx = page_info["page_idx"]

        try:
            # Extract char information from PDF page
            pdf_page = pdf_doc[page_idx]
            page_dict = get_page(pdf_page)

            # Collect all chars from the page
            all_chars = []
            for block in page_dict.get('blocks', []):
                for line in block.get('lines', []):
                    # Skip rotated lines
                    if 0 < abs(line.get('rotation', 0)) < 90:
                        continue
                    for span_dict in line.get('spans', []):
                        for char in span_dict.get('chars', []):
                            all_chars.append(char)

            # Process preproc_blocks
            blocks = page_info.get("preproc_blocks", [])
            _restore_chars_to_blocks(blocks, all_chars)

            # Process discarded_blocks
            discarded_blocks = page_info.get("discarded_blocks", [])
            _restore_chars_to_blocks(discarded_blocks, all_chars)

        except Exception as e:
            logger.warning(f"Failed to restore chars for page {page_idx}: {e}")
            continue

    return middle_json


def _restore_chars_to_blocks(blocks: List[Dict[str, Any]], all_chars: List[Dict[str, Any]]):
    """
    Restore chars to blocks (helper function).

    Args:
        blocks: List of blocks
        all_chars: List of all chars from the page
    """
    for block in blocks:
        for line in block.get("lines", []):
            for span in line.get("spans", []):
                # Only process text-type spans
                if span.get("type") in ["text", "inline_equation"]:
                    span['chars'] = []
                    span_bbox = span['bbox']

                    # Find chars that overlap with this span
                    for char in all_chars:
                        if is_char_in_span_bbox(char['bbox'], span_bbox):
                            span['chars'].append(char)

                    # Convert chars to content (keeping chars)
                    if len(span['chars']) > 0:
                        chars_to_content_keep(span, keep_chars=True)
                    else:
                        # No chars found, keep existing content
                        span['content'] = span.get('content', '')


async def aio_layout_ocr_parse(
    output_dir: str,
    pdf_file_names: List[str],
    pdf_bytes_list: List[bytes],
    p_lang_list: List[str],
    parse_method: str = "auto",
    start_page_id: int = 0,
    end_page_id: Optional[int] = None,
    **kwargs,
) -> List[Dict[str, Any]]:
    """
    Independent parsing pipeline for layout_ocr API.
    Uses existing MinerU pipeline but preserves character information.

    Strategy:
    1. Call existing pipeline's doc_analyze for layout analysis
    2. Call existing result_to_middle_json to generate middle_json
    3. Re-extract chars from PDF and map to spans
    4. Return middle_json with chars preserved

    Args:
        output_dir: Output directory for temporary files
        pdf_file_names: List of PDF file names
        pdf_bytes_list: List of PDF bytes
        p_lang_list: List of OCR languages
        parse_method: Parsing method (auto/ocr/txt)
        start_page_id: Start page index
        end_page_id: End page index
        **kwargs: Additional arguments

    Returns:
        List of middle_json dictionaries with chars information
    """
    from mineru.backend.pipeline.pipeline_analyze import doc_analyze
    from mineru.backend.pipeline.model_json_to_middle_json import result_to_middle_json
    from mineru.cli.common import prepare_env, _prepare_pdf_bytes
    from mineru.data.data_reader_writer import FileBasedDataWriter

    # Prepare PDF bytes
    pdf_bytes_list = _prepare_pdf_bytes(pdf_bytes_list, start_page_id, end_page_id)

    # Run pipeline analysis (using existing function)
    logger.info("Running layout analysis with MinerU pipeline...")
    infer_results, all_image_lists, all_pdf_docs, lang_list, ocr_enabled_list = doc_analyze(
        pdf_bytes_list, p_lang_list, parse_method=parse_method,
        formula_enable=True, table_enable=True
    )

    # Generate middle_json
    middle_json_list = []
    for idx, model_list in enumerate(infer_results):
        pdf_file_name = pdf_file_names[idx]
        local_image_dir, local_md_dir = prepare_env(output_dir, pdf_file_name, parse_method)
        image_writer = FileBasedDataWriter(local_image_dir)

        images_list = all_image_lists[idx]
        pdf_doc = all_pdf_docs[idx]
        _lang = lang_list[idx]
        _ocr_enable = ocr_enabled_list[idx]

        # Generate middle_json using existing pipeline
        logger.info(f"Generating middle_json for {pdf_file_name}...")
        middle_json = result_to_middle_json(
            model_list, images_list, pdf_doc, image_writer,
            _lang, _ocr_enable, formula_enabled=True
        )

        # ⚠️ Restore chars information
        logger.info(f"Restoring character information for {pdf_file_name}...")
        middle_json = restore_chars_to_middle_json(middle_json, pdf_doc)

        middle_json_list.append(middle_json)

    return middle_json_list


def format_layout_ocr_result(
    middle_json_list: List[Dict[str, Any]],
    pdf_file_names: List[str],
    include_discarded: bool = False
) -> Dict[str, Any]:
    """
    Format middle_json to layout_ocr API response format.

    Args:
        middle_json_list: List of middle_json dictionaries
        pdf_file_names: List of PDF file names
        include_discarded: Whether to include discarded blocks (headers/footers)

    Returns:
        Formatted response dictionary
    """
    from mineru.version import __version__

    result = {
        "status": "success",
        "backend": "pipeline",
        "version": __version__,
        "files": []
    }

    for pdf_idx, middle_json in enumerate(middle_json_list):
        file_result = {
            "filename": pdf_file_names[pdf_idx],
            "pages": []
        }

        for page_info in middle_json.get("pdf_info", []):
            page_data = {
                "page_index": page_info["page_idx"],
                "page_size": {
                    "width": page_info["page_size"][0],
                    "height": page_info["page_size"][1]
                },
                "layout_boxes": []
            }

            box_id = 0

            # Process main blocks (para_blocks or preproc_blocks)
            blocks = page_info.get("para_blocks") or page_info.get("preproc_blocks", [])
            for block in blocks:
                layout_box = format_block_to_layout_box(block, box_id)
                if layout_box:
                    page_data["layout_boxes"].append(layout_box)
                    box_id += 1

            # Process discarded blocks if requested
            if include_discarded:
                page_data["discarded_boxes"] = []
                for block in page_info.get("discarded_blocks", []):
                    layout_box = format_block_to_layout_box(block, box_id)
                    if layout_box:
                        layout_box["is_discarded"] = True
                        page_data["discarded_boxes"].append(layout_box)
                        box_id += 1

            file_result["pages"].append(page_data)

        result["files"].append(file_result)

    return result


def format_block_to_layout_box(block: Dict[str, Any], box_id: int) -> Optional[Dict[str, Any]]:
    """
    Convert a block to layout_box format.

    Args:
        block: Block dictionary (preproc_block or para_block)
        box_id: Box ID

    Returns:
        layout_box dictionary or None if invalid
    """
    block_type = block.get("type")
    if not block_type:
        return None

    # Basic information
    layout_box = {
        "box_id": box_id,
        "box_type": block_type,
        "bbox": block.get("bbox"),
    }

    # Add group_id if present (for tables/images)
    if "group_id" in block:
        layout_box["group_id"] = block["group_id"]

    # Process lines
    lines = block.get("lines", [])
    layout_box["lines"] = []

    for line_idx, line in enumerate(lines):
        line_data = {
            "line_index": line.get("index", line_idx),
            "bbox": line.get("bbox"),
            "spans": []
        }

        # Process spans
        for span in line.get("spans", []):
            span_data = {
                "type": span.get("type"),
                "bbox": span.get("bbox"),
                "score": span.get("score"),
                "content": span.get("content", "")
            }

            # Add special type-specific data
            span_type = span.get("type")
            if span_type == "table":
                if "html" in span:
                    span_data["html"] = span["html"]
                if "latex" in span:
                    span_data["latex"] = span["latex"]
            elif span_type == "image":
                if "image_path" in span:
                    span_data["image_path"] = span["image_path"]
            elif span_type in ["interline_equation", "inline_equation"]:
                if "latex" in span:
                    span_data["latex"] = span["latex"]

            # Add characters if present
            if "chars" in span and len(span["chars"]) > 0:
                span_data["characters"] = [
                    {
                        "char": char["char"],
                        "bbox": char["bbox"],
                        "char_index": char.get("char_idx", i)
                    }
                    for i, char in enumerate(span["chars"])
                ]

            line_data["spans"].append(span_data)

        # Generate line text
        line_text = " ".join(
            span.get("content", "")
            for span in line.get("spans", [])
            if span.get("type") in ["text", "inline_equation"]
        )
        line_data["text"] = line_text.strip()

        layout_box["lines"].append(line_data)

    return layout_box
